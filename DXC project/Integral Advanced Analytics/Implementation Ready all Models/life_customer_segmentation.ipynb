{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Life Customer Segmentation\n",
    "## Data used for analysis is based on Integral Life Admin System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SQL query in below cells will retreive data based on database credentials provide. Right now these credentials have been left empty for security reasons. Please enter relevant details before running this notebook further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc \n",
    "\n",
    "# Settings to view all columns and rows\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter ip address and port number of the system where the database resides.\n",
    "server   = '10.0.3.98'\n",
    "database = 'INT77DB_R212'\n",
    "username = 'sisensedb_user'\n",
    "password = 'Sisense12#$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5b111b10e556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Add appropriate driver name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcnxn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyodbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DRIVER={SQL Server};SERVER='\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m';DATABASE='\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m';UID='\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m';PWD='\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mpassword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnxn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53)')"
     ]
    }
   ],
   "source": [
    "# Add appropriate driver name\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Query\n",
    "query = '''\n",
    "select \n",
    "q1.clntnum as 'Client Number',\n",
    "q1.clttype as 'Client Type' ,\n",
    "q1.cltsex  as 'Client Sex' ,\n",
    "q1.cltdob  as 'Client Date of Birth',\n",
    "q1.marryd  as 'Client Marital Status',\n",
    "q1.[client name] as 'Client Name'\n",
    "from\n",
    "\n",
    "(select clntnum, clttype, ( rtrim(givname) + ' ' + rtrim(surname) ) as 'client name', cltsex, cltdob, marryd from vm1dta.clntpf where validflag = '1')q1\n",
    "order by q1.clntnum\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df_source = pd.read_sql(query,cnxn)\n",
    "\n",
    "# Close the cursor\n",
    "cursor.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check row and column count \n",
    "df_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type for Client Number\n",
    "df_source['Client Number'] = df_source['Client Number'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes \n",
    "df_source.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Customer Life Time Value Data\n",
    "\n",
    "df_cltv = pd.read_csv('C:\\ProgramData\\Sisense\\PrismServer\\ElastiCubeData\\EX_SOURCE_CLTVSCORE_LIFE.csv', usecols = ['clntnum', 'cltvband','client_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names\n",
    "df_cltv = df_cltv.rename(columns={\"clntnum\":\"Client Number\", \"cltvband\":\"CLTV Band\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check row and column count \n",
    "df_cltv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes \n",
    "df_cltv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type for Client Number\n",
    "df_cltv['Client Number'] = df_cltv['Client Number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cltv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge source dataframe and cltv dataframe\n",
    "\n",
    "df_merge_01 = pd.merge(df_source, df_cltv, on=\"Client Number\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null columns\n",
    "\n",
    "df_merge_01.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check size of the dataframe\n",
    "\n",
    "df_merge_01.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first few rows\n",
    "\n",
    "df_merge_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Customer Propensity to Buy Data\n",
    "\n",
    "df_propensity = pd.read_csv('C:\\ProgramData\\Sisense\\PrismServer\\ElastiCubeData\\EX_SOURCE_CUSTOMER_PROPENSITY_LIFE.csv', usecols=['CLIENT_NUMBER','buy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names\n",
    "df_propensity = df_propensity.rename(columns={\"CLIENT_NUMBER\":\"Client Number\", \"buy\":\"Propensity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check row and column count \n",
    "df_propensity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes \n",
    "df_propensity.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first few rows\n",
    "\n",
    "df_propensity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type for Client Number\n",
    "df_propensity['Client Number'] = df_propensity['Client Number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad leading zeroes in case client number does not have them\n",
    "\n",
    "df_propensity['Client Number']=df_propensity['Client Number'].apply(lambda i: '{0:0>8}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge source dataframe and cltv dataframe\n",
    "\n",
    "df_merge_02 = pd.merge(df_merge_01, df_propensity, on=\"Client Number\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null columns\n",
    "\n",
    "df_merge_02.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check size of the dataframe\n",
    "\n",
    "df_merge_02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect first few rows \n",
    "\n",
    "df_merge_02.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv which has Indian Population and City details\n",
    "\n",
    "india_geo = pd.read_csv('C:\\ProgramData\\Sisense\\PrismServer\\ElastiCubeData\\india.csv', usecols = ['City','Lat','Lng','Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first few rows\n",
    "\n",
    "india_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all cities in a list\n",
    "\n",
    "cities=india_geo['City'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge it with second dataframe\n",
    "\n",
    "df_merge_02['City'] = np.random.choice(list(cities), len(df_merge_02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both datframes to get a new dataframe\n",
    "\n",
    "df_merge_03 = pd.merge(df_merge_02, india_geo, on=\"City\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect first few rows\n",
    "\n",
    "df_merge_03.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Tier' based on population (based on https://en.wikipedia.org/wiki/Classification_of_Indian_cities)\n",
    "conditions = [\n",
    "    (df_merge_03['Population'] >0 ) & (df_merge_03['Population'] < 5000),\n",
    "    (df_merge_03['Population'] >= 5000) & (df_merge_03['Population'] < 9999),\n",
    "    (df_merge_03['Population'] >= 9999) & (df_merge_03['Population'] < 19999),\n",
    "    (df_merge_03['Population'] >= 20000) & (df_merge_03['Population'] < 49999),\n",
    "    (df_merge_03['Population'] >= 50000) & (df_merge_03['Population'] < 99999),\n",
    "    (df_merge_03['Population'] >= 100000)]\n",
    "choices = ['Tier-6', 'Tier-5', 'Tier-4', 'Tier-3', 'Tier-2', 'Tier-1']\n",
    "\n",
    "df_merge_03['Tier'] = np.select(conditions, choices, default='Tier-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Population_Classification' based on population (based on https://en.wikipedia.org/wiki/Classification_of_Indian_cities)\n",
    "conditions = [\n",
    "    (df_merge_03['Population'] >0 ) & (df_merge_03['Population'] < 9999),\n",
    "    (df_merge_03['Population'] >= 9999) & (df_merge_03['Population'] < 99999),\n",
    "    (df_merge_03['Population'] >= 99999) & (df_merge_03['Population'] < 999999),\n",
    "    (df_merge_03['Population'] >= 999999)]\n",
    "choices = ['Rural', 'Semi-Urban', 'Urban', 'Metropolitan']\n",
    "\n",
    "df_merge_03['Population Class'] = np.select(conditions, choices, default='Rural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for customer Age\n",
    "df_merge_03['Customer Age'] = np.random.randint(18,70,size=len(df_merge_03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for customer job profile\n",
    "profession = ['White Collar Job', 'Blue Collar Job', 'Other']\n",
    "df_merge_03['Profession Category'] = np.random.choice(list(profession), len(df_merge_03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output in a csv file\n",
    "df_merge_03.to_csv('EX_SOURCE_CUSTOMER_SEGMENTATION_LIFE.csv', index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
